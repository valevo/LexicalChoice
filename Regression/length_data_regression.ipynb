{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import refexps\n",
    "from os import listdir, path\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from scipy import stats, integrate\n",
    "from refexps import get_previous\n",
    "import pickle\n",
    "from refexps import load_data, move_level, gamerun_level, get_previous #, lex_sim\n",
    "from os import listdir, path\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import compound_splitter\n",
    "from scipy import stats\n",
    "from nltk import word_tokenize\n",
    "from string import punctuation\n",
    "punct = list(punctuation)\n",
    "import compound_splitter\n",
    "\n",
    "dataset_dir = '../En_De_Dataset/All/RefExp'\n",
    "success_dir = '../En_De_Dataset/All/Success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp_len(exp, language, splits, compound):\n",
    "    '''\n",
    "    Extract content words by the phrase\n",
    "    :param exp: referring expression tuple\n",
    "    :return: set of content words of the phrase\n",
    "    '''\n",
    "    exp = exp[2]\n",
    "    words = word_tokenize(exp, language)\n",
    "    if compound == True:\n",
    "        if language == 'german':\n",
    "            words_nocomp = []\n",
    "            for w in words:\n",
    "                word = compound_splitter.split_word(w, splits)\n",
    "                words_nocomp = words_nocomp + (word.split(' '))\t\n",
    "                words = words_nocomp\n",
    "    return len(words)\n",
    "\n",
    "def len_div(exp1, exp2, language, splits, compound):\n",
    "    '''\n",
    "    compute dice similarity between the content words in two referring expression\n",
    "    :param exp1: referring expression tuple 1\n",
    "    :param exp2: referring expression tuple 2\n",
    "    :return: dice similarity between the content words in the expressions; undefined if they have none\n",
    "    '''        \n",
    "    len1 = exp_len(exp1, language, splits, compound)    \n",
    "    len2 = exp_len(exp2, language, splits, compound)\n",
    "    if exp1 is 'no_previous' or exp2 is 'no_previous':\n",
    "        return 'undefined'\n",
    "    if len1 + len2 == 0:\n",
    "        return 'undefined'\n",
    "    metric = float(len1 - len2)/float(len1 + len2)\n",
    "    return metric if not np.isnan(metric) and metric > -1  and metric < 1 else 'undefined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_values_move(refexps_dir, success_dir, compound = True):  \n",
    "    splits = compound_splitter.load_dict('../de_lower.dict')\n",
    "    move_level_data = defaultdict(dict)\n",
    "    success_types = set()\n",
    "    for dialogue in listdir(refexps_dir):\n",
    "        #extract dialogue type\n",
    "        success_file = dialogue.replace('refexps', 'movesuccess')\n",
    "        success_file = path.join(success_dir, success_file)\n",
    "        if dialogue.startswith('FTT'):\n",
    "            language = 'german'\n",
    "        else:\n",
    "            language = 'english'\n",
    "        dialogue_path = path.join(refexps_dir, dialogue)\n",
    "        #load referring expressions data\n",
    "        dialogue_path = refexps.load_data(dialogue_path)\n",
    "        success_moves = refexps.load_data(success_file)\n",
    "        #move level\n",
    "        dialogue_move = refexps.move_level(dialogue_path)\n",
    "        #iterate over moves\n",
    "        for move in dialogue_move:\n",
    "            move_id = dialogue + str(move[0])\n",
    "            success = success_moves[move[0]]\n",
    "            refs = move[1]\n",
    "            if success == 'success':\n",
    "                success = 'correct'\n",
    "            if success == 'wrong':\n",
    "                success = 'incorrect'\n",
    "            if success == 'na':\n",
    "                success = 'no_video'\n",
    "            success_types.add(success)\n",
    "            if success == 'no_video':\n",
    "                pass\n",
    "            else:\n",
    "                refs = move[1]\n",
    "                #iterate over objects\n",
    "                for obj in refs:\n",
    "                    #iterate over objects\n",
    "                    refobj = refs[obj]\n",
    "                    #SIMILARITY OF LEXICAL CONTENT INTO\n",
    "                    sim_align = []\n",
    "                    sim_align_speaker = defaultdict(list)\n",
    "                    sim_coherence_speaker = defaultdict(list)\n",
    "                    sim_coherence = []\n",
    "                    for ref in refobj:\n",
    "                        speaker = ref[1]\n",
    "                        sim = len_div(ref, get_previous(ref, refobj), language, splits, compound) ###\n",
    "                        if sim != 'undefined':\n",
    "                            sim_align.append(sim)\n",
    "                            sim_align_speaker[speaker].append(sim)\n",
    "                    sim_align = np.mean(sim_align)\n",
    "                    comb_ref = combinations(refobj,2)\n",
    "                    for comb in comb_ref:\n",
    "                        if comb[0] != comb[1]:\n",
    "                            sim = len_div(comb[0], comb[1], language, splits, compound) ###\n",
    "                            if sim != 'undefined':\n",
    "                                sim_coherence.append(sim)\n",
    "                                sim_coherence_speaker[comb[0][1]].append(sim)\n",
    "                                sim_coherence_speaker[comb[1][1]].append(sim)\n",
    "                    sim_coherence = np.mean(sim_coherence)\n",
    "                    #movelevel coherence and alignment (for each object)\n",
    "                    if not np.isnan(sim_coherence):\n",
    "                        move_level_data['coherence'][move_id] = (sim_coherence, success)\n",
    "                    if not np.isnan(sim_align):\n",
    "                        move_level_data['alignment'][move_id] = (sim_align, success)\n",
    "                    for s in sim_align_speaker:\n",
    "                        if not np.isnan(np.mean(sim_align_speaker[s])):\n",
    "                            move_level_data['alignment '+s.replace('-utts', '')][move_id] = (np.mean(sim_align_speaker[s]), success )\n",
    "                    for s in sim_coherence_speaker:\n",
    "                        if not np.isnan(np.mean(sim_coherence_speaker[s])) :\n",
    "                            move_level_data['coherence '+s.replace('-utts', '')][move_id] = (np.mean(sim_coherence_speaker[s]), success)\n",
    "    return move_level_data\n",
    "\n",
    "move_level_data  = data_values_move(dataset_dir, success_dir)\n",
    "pickle.dump(move_level_data, open('move_lvl_regress_len.p', 'w'))\n",
    "data_regression = {}\n",
    "for v in move_level_data:\n",
    "    data_regression[v] = move_level_data[v].values()\n",
    "pickle.dump(data_regression, open('regression_length.p', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alignment e FTT_2006-06-22pair1_refexps.p(2820, 3210) (-0.14285714285714285, 'correct')\n",
      "\n",
      "\n",
      "coherence p FTT_2006-06-22pair1_refexps.p(2820, 3210) (0.14285714285714285, 'correct')\n",
      "\n",
      "\n",
      "coherence FTT_2006-06-22pair1_refexps.p(2820, 3210) (0.14285714285714285, 'correct')\n",
      "\n",
      "\n",
      "alignment p 20070201_run3pento_nonoise_refexps.p(1094, 1153) (0.5714285714285714, 'correct')\n",
      "\n",
      "\n",
      "coherence e FTT_2006-06-22pair1_refexps.p(2820, 3210) (0.14285714285714285, 'correct')\n",
      "\n",
      "\n",
      "alignment FTT_2006-06-22pair1_refexps.p(2820, 3210) (-0.14285714285714285, 'correct')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, val in move_level_data.iteritems():\n",
    "    print key, val.keys()[0], val.values()[0]\n",
    "    print '\\n'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
