{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import refexps\n",
    "from os import listdir, path\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pickle\n",
    "\n",
    "dataset_dir = '../En_De_Dataset/All/RefExp'\n",
    "success_dir = '../En_De_Dataset/All/Success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "lex_sim() takes at least 4 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ff599b94e989>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mref\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrefobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mspeaker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefexps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlex_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefexps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_previous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'undefined'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msim_align_speaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeaker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: lex_sim() takes at least 4 arguments (2 given)"
     ]
    }
   ],
   "source": [
    "move_level_data = {'alignment e':{}, 'alignment p': {}, 'coherence e':{}, 'coherence p': {}, 'alignment':{}, 'coherence':{}}\n",
    "\n",
    "for dialogue in listdir(dataset_dir):\n",
    "    splits = compound_splitter.load_dict('de_lower.dict')\n",
    "    #extract dialogue type\n",
    "    success_file = dialogue.replace('refexps', 'movesuccess')\n",
    "    success_file = path.join(success_dir, success_file)\n",
    "    dialogue_path = path.join(dataset_dir, dialogue)\n",
    "    #load referring expressions data\n",
    "    dialogue_data = refexps.load_data(dialogue_path)\n",
    "    success_moves = refexps.load_data(success_file)\n",
    "    #move level\n",
    "    dialogue_move = refexps.move_level(dialogue_data)\n",
    "    #iterate over moves\n",
    "    for move in dialogue_move:\n",
    "        move_id = dialogue + str(move[0])\n",
    "        success = success_moves[move[0]]\n",
    "        if success == 'no_video':\n",
    "            continue\n",
    "        refs = move[1]\n",
    "        #iterate over objects\n",
    "        for obj in refs:\n",
    "            #iterate over objects\n",
    "            refobj = refs[obj]\n",
    "            sim_align = []\n",
    "            sim_align_speaker = {}\n",
    "            sim_coherence_speaker = {}\n",
    "            sim_coherence = []\n",
    "            for ref in refobj:\n",
    "                speaker = ref[1]\n",
    "                sim = refexps.lex_sim(ref, refexps.get_previous(ref, refobj, language, splits)\n",
    "                if sim != 'undefined':\n",
    "                    if not sim_align_speaker.has_key(speaker):\n",
    "                        sim_align_speaker[speaker] = []\n",
    "                    sim_align_speaker[speaker].append(sim)\n",
    "            comb_ref = combinations(refobj,2)\n",
    "            for comb in comb_ref:\n",
    "                if comb[0] != comb[1]:\n",
    "                    sim = refexps.lex_sim(comb[0], comb[1], language, splits)\n",
    "                    if sim != 'undefined':\n",
    "                        sim_coherence.append(sim)\n",
    "                        if not sim_coherence_speaker.has_key(comb[0][1]):\n",
    "                            sim_coherence_speaker[comb[0][1]] = []\n",
    "                        if not sim_coherence_speaker.has_key(comb[1][1]):\n",
    "                            sim_coherence_speaker[comb[1][1]] = []\n",
    "                        sim_coherence_speaker[comb[0][1]].append(sim)\n",
    "                        sim_coherence_speaker[comb[1][1]].append(sim)\n",
    "            #movelevel coherence and alignment (for each object)\n",
    "            for s in sim_align_speaker:\n",
    "                if not np.isnan(np.mean(sim_align_speaker[s])) :\n",
    "                    move_level_data[ 'alignment '+ s.replace('-utts', '')][move_id] = (np.mean(sim_align_speaker[s]), success)\n",
    "            for s in sim_coherence_speaker:\n",
    "                if not np.isnan(np.mean(sim_coherence_speaker[s])):\n",
    "                    move_level_data['coherence '+ s.replace('-utts', '')][move_id] = (np.mean(sim_coherence_speaker[s]), success)\n",
    "            \n",
    "pickle.dump(move_level_data, open('regression_lexical.p', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_lexical' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7b1097886da5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_lexical\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mlex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_lexical' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
