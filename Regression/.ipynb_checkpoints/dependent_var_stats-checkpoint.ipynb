{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from DataObjs import Corpus, success_transform, confidence_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "115\n",
      "164\n",
      "0.701219512195\n"
     ]
    }
   ],
   "source": [
    "with open('Data/data_regression.p') as handle:\n",
    "    raw_data = pickle.load(handle)\n",
    "    \n",
    "# length, lex, form -> all, p, e\n",
    "\n",
    "# data point = (sccss_str, conf_str, ([], [], []), ([], [], []), ([], [], []))     \n",
    "    \n",
    "# nonoise\n",
    "data_en = Corpus(raw_data[1], succs_map=success_transform, conf_map=confidence_transform)\n",
    "# FTT\n",
    "data_de = Corpus(raw_data[0], succs_map=success_transform, conf_map=confidence_transform) \n",
    "\n",
    "data_all = Corpus(dict(raw_data[0], **raw_data[1]), succs_map=success_transform, conf_map=confidence_transform)\n",
    "\n",
    "print len(data_en)\n",
    "print len(data_de)\n",
    "print len(data_all)\n",
    "print float(len(data_de))/len(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.6869565217391305, 12.782608695652174, 9.8, 21.730434782608697]\n",
      "[0, 3, 2, 44]\n",
      "probability of sample under H0 1.99790782162e-28\n",
      "probability of sample under emp 0.0639820092446\n",
      "Significance 3.06043414173e-27\n",
      "Counter({4: 51, 2: 30, 3: 23, 1: 11})\n",
      "[0, 3, 2, 44]\n",
      "Power_divergenceResult(statistic=47.028092770382315, pvalue=3.4281114742444467e-10)\n"
     ]
    }
   ],
   "source": [
    "from math import factorial\n",
    "from collections import Counter\n",
    "\n",
    "theoretical_data = data_de\n",
    "observed_data = data_en\n",
    "cur_var = Corpus.get_confs\n",
    "\n",
    "obs_n = len(observed_data)\n",
    "theo_probs = [v/float(len(theoretical_data)) for k, v in sorted(Counter(theoretical_data.get_confs()).iteritems())]\n",
    "obs_probs = [v/float(len(observed_data)) for k, v in sorted(Counter(observed_data.get_confs()).iteritems())]\n",
    "\n",
    "cats = sorted(set(cur_var(theoretical_data)).union(set(cur_var(observed_data))))\n",
    "theo_counts = Counter(cur_var(theoretical_data))\n",
    "theo_exp_counts = [theo_counts[c]/float(len(cur_var(theoretical_data))) if c in theo_counts else 0 for c in cats]\n",
    "theo_exp_counts = [obs_n*exp_c for exp_c in theo_exp_counts]\n",
    "obs_counts = Counter(cur_var(observed_data))\n",
    "obs_counts = [obs_counts[c] if c in obs_counts else 0 for c in cats]\n",
    "\n",
    "print theo_exp_counts\n",
    "print obs_counts\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Multinomial_test\n",
    "def p(probs, counts): \n",
    "    result = factorial(sum(counts))\n",
    "    for prob, count in zip(probs, counts):\n",
    "        result *= prob ** count / factorial(count)\n",
    "    return result\n",
    "\n",
    "z = [b for a, b in sorted(Counter(observed_data.get_confs()).items())]\n",
    "possibles = [(i, j, k) for i in range(obs_n+1) for j in range(obs_n+1) \n",
    "                         for k in range(obs_n+1) if i + j + k == obs_n]\n",
    "assert tuple(z) in possibles\n",
    "\n",
    "P0 = p(theo_probs, z)\n",
    "print 'probability of sample under H0', P0\n",
    "print 'probability of sample under emp', p(obs_probs, z)\n",
    "Psig = 0\n",
    "for possible in possibles:\n",
    "    P = p(theo_probs, possible)\n",
    "    #print(\"{}: {}\".format(possible, P))\n",
    "    if P <= P0:\n",
    "        Psig += P\n",
    "print 'Significance', Psig\n",
    "\n",
    "print theo_counts\n",
    "print obs_counts\n",
    "\n",
    "print stats.power_divergence(f_obs=obs_counts, f_exp=theo_exp_counts, lambda_='log-likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n 115.0\n"
     ]
    }
   ],
   "source": [
    "# measure frequencies\n",
    "succs_counts = Counter(data_de.get_succs())\n",
    "\n",
    "conf_counts = Counter(data_de.get_confs())\n",
    "\n",
    "succ_confs = list(zip(data_de.get_succs(), data_de.get_confs()))\n",
    "\n",
    "joint_counts = Counter(succ_confs)\n",
    "\n",
    "n = float(sum(joint_counts.values()))\n",
    "print 'n', n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 52, 1: 47, -1: 16})\n",
      "Probs: {0: 0.45217391304347826, 1: 0.40869565217391307, -1: 0.1391304347826087}\n",
      "entropy (%): 0.909322374784\n"
     ]
    }
   ],
   "source": [
    "# success statistics\n",
    "\n",
    "print succs_counts\n",
    "print 'Probs:', {k: v/n for k, v in succs_counts.iteritems()}\n",
    "print 'entropy (%):', -sum([float(c)/n * np.log2(float(c)/n) for c in succs_counts.values()])/ np.log2(len(succs_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({4: 51, 2: 30, 3: 23, 1: 11})\n",
      "Probs: {1: 0.09565217391304348, 2: 0.2608695652173913, 3: 0.2, 4: 0.4434782608695652}\n",
      "entropy (%): 0.907109881546\n"
     ]
    }
   ],
   "source": [
    "# confidence statistics\n",
    "\n",
    "print conf_counts\n",
    "print 'Probs:', {k: v/n for k, v in conf_counts.iteritems()}\n",
    "print 'entropy (%):', -sum([float(c)/n * np.log2(float(c)/n) for c in conf_counts.values()])/np.log2(len(conf_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1\t2\t3\t4\n",
      "---------------------------------\n",
      "\n",
      "5 \t2 \t1 \t8 \t| -1 \n",
      "\n",
      "1 \t28 \t22 \t1 \t| 0 \n",
      "\n",
      "5 \t0 \t0 \t42 \t| 1 \n",
      "\n",
      "\n",
      "\n",
      "1\t2\t3\t4\n",
      "---------------------------------\n",
      "\n",
      "0.043 \t0.017 \t0.009 \t0.07 \t| -1 \n",
      "\n",
      "0.009 \t0.243 \t0.191 \t0.009 \t| 0 \n",
      "\n",
      "0.043 \t0.0 \t0.0 \t0.365 \t| 1 \n",
      "\n",
      "\n",
      "\n",
      "dependence (scaled I):  0.342716909302\n",
      "\n",
      "sqrt(chi2/n): 0.961860204756\n",
      "\tp-value: 1.15789241521e-20\n",
      "\tdof: 6\n"
     ]
    }
   ],
   "source": [
    "# contingencies\n",
    "joint_table = []\n",
    "print '\\n\\n1\\t2\\t3\\t4'\n",
    "print '---------------------------------\\n'\n",
    "for succ in [-1, 0, 1]:\n",
    "    cur_row = []\n",
    "    for conf in [1, 2, 3, 4]:\n",
    "        cur_p = joint_counts[(succ, conf)]\n",
    "        cur_row.append(cur_p)\n",
    "        print cur_p, '\\t',\n",
    "    joint_table.append(cur_row)\n",
    "    print '|', succ, '\\n'\n",
    "\n",
    "    \n",
    "print '\\n\\n1\\t2\\t3\\t4'\n",
    "print '---------------------------------\\n'\n",
    "for succ in [-1, 0, 1]:\n",
    "    for conf in [1, 2, 3, 4]:\n",
    "        cur_p = round(joint_counts[(succ, conf)]/float(n), 3)\n",
    "        print cur_p, '\\t',\n",
    "    print '|', succ, '\\n'\n",
    "    \n",
    "H_succ = -sum([float(c)/n * np.log2(float(c)/n) for c in succs_counts.values()])\n",
    "H_conf = -sum([float(c)/n * np.log2(float(c)/n) for c in conf_counts.values()])\n",
    "H_joint = -sum([float(c)/n * np.log2(float(c)/n) for c in joint_counts.values()])\n",
    "\n",
    "print '\\n\\ndependence (scaled I): ', (H_succ + H_conf - H_joint)/H_joint\n",
    "print '\\nsqrt(chi2/n):', (stats.chi2_contingency(joint_table)[0]/float(n))**0.5\n",
    "print '\\tp-value:', stats.chi2_contingency(joint_table)[1]\n",
    "print '\\tdof:', stats.chi2_contingency(joint_table)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(confidence_lvl | success_lvl)\n",
      "\n",
      "1\t2\t3\t4\n",
      "---------------------------------\n",
      "\n",
      "0.3125 \t0.125 \t0.0625 \t0.5 \t| -1 \n",
      "\n",
      "0.0192 \t0.5385 \t0.4231 \t0.0192 \t| 0 \n",
      "\n",
      "0.1064 \t0.0 \t0.0 \t0.8936 \t| 1 \n",
      "\n",
      "entropies [1.1432752061942137, 0.84903147657617706, 0.33892183540531451] (max =  1.38629436112 )\n",
      "\n",
      "\n",
      "P(success_lvl | confidence_lvl)\n",
      "\n",
      "-1\t0\t1\n",
      "-------------------------\n",
      "\n",
      "0.4545 \t0.0909 \t0.4545 \t| 1 \n",
      "\n",
      "0.0667 \t0.9333 \t0.0 \t| 2 \n",
      "\n",
      "0.0435 \t0.9565 \t0.0 \t| 3 \n",
      "\n",
      "0.1569 \t0.0196 \t0.8235 \t| 4 \n",
      "\n",
      "entropies [0.93476989785827924, 0.2450179864450992, 0.17891210361100607, 0.52759031766068332] (max =  1.09861228867 )\n"
     ]
    }
   ],
   "source": [
    "# conditional probabilities\n",
    "\n",
    "succ_marg_probs = {k: v/n for k, v in succs_counts.iteritems()}\n",
    "conf_marg_probs = {k: v/n for k, v in conf_counts.iteritems()}\n",
    "joint_probs = {k: v/n for k, v in joint_counts.iteritems()}\n",
    "\n",
    "joint_table = []\n",
    "\n",
    "print 'P(confidence_lvl | success_lvl)'\n",
    "print '\\n1\\t2\\t3\\t4'\n",
    "print '---------------------------------\\n'\n",
    "for succ in [-1, 0, 1]:\n",
    "    cur_row = []\n",
    "    for conf in [1, 2, 3, 4]:\n",
    "        joint_p = joint_probs[(succ, conf)] if (succ, conf) in joint_probs else 0.0\n",
    "        cur_p = round(joint_p/succ_marg_probs[succ], 4)\n",
    "        cur_row.append(cur_p)\n",
    "        print cur_p, '\\t',\n",
    "    joint_table.append(cur_row)\n",
    "    print '|', succ, '\\n'\n",
    "    \n",
    "print 'entropies', [stats.entropy(row) for row in joint_table], '(max = ', np.log(4), ')'\n",
    "\n",
    "joint_table = []\n",
    "    \n",
    "print '\\n\\nP(success_lvl | confidence_lvl)'\n",
    "print '\\n-1\\t0\\t1'\n",
    "print '-------------------------\\n'\n",
    "for conf in [1, 2, 3, 4]:\n",
    "    cur_row = []\n",
    "    for succ in [-1, 0, 1]:\n",
    "        joint_p = joint_probs[(succ, conf)] if (succ, conf) in joint_probs else 0.0\n",
    "        cur_p = round(joint_p/conf_marg_probs[conf], 4)\n",
    "        cur_row.append(cur_p)\n",
    "        print cur_p, '\\t',\n",
    "    joint_table.append(cur_row)\n",
    "    print '|', conf, '\\n'\n",
    "\n",
    "print 'entropies', [stats.entropy(row) for row in joint_table], '(max = ', np.log(3), ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
