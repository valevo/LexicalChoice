{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import refexps\n",
    "from os import listdir, path\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import nltk\n",
    "from scipy import stats\n",
    "import compound_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_values_move(refexps_dir, success_dir):\n",
    "    splits = compound_splitter.load_dict('de_lower.dict')\n",
    "    move_level_data = defaultdict(dict)\n",
    "    move_level_align = []\n",
    "    move_level_coherence = []\n",
    "    success_types = set()\n",
    "    playermove_level_align_speaker = defaultdict(list)\n",
    "    playermove_level_coherence_speaker= defaultdict(list)\n",
    "\n",
    "    for dialogue in listdir(refexps_dir):\n",
    "        #extract dialogue type\n",
    "        success_file = dialogue.replace('refexps', 'movesuccess')\n",
    "        success_file = path.join(success_dir, success_file)\n",
    "        if dialogue.startswith('FTT'):\n",
    "            language = 'german'\n",
    "        else:\n",
    "            language = 'english'\n",
    "        dialogue = path.join(refexps_dir, dialogue)\n",
    "        #load referring expressions data\n",
    "        dialogue = refexps.load_data(dialogue)\n",
    "        success_moves = refexps.load_data(success_file)\n",
    "        #move level\n",
    "        dialogue_move = refexps.move_level(dialogue)\n",
    "        #iterate over moves\n",
    "        for move in dialogue_move:\n",
    "            refs = move[1]\n",
    "            #iterate over objects\n",
    "            for obj in refs:\n",
    "                #iterate over objects\n",
    "                refobj = refs[obj]\n",
    "                #SIMILARITY OF LEXICAL CONTENT INTO\n",
    "                sim_align = []\n",
    "                sim_align_speaker = defaultdict(list)\n",
    "                sim_coherence_speaker = defaultdict(list)\n",
    "                sim_coherence = []\n",
    "                for ref in refobj:\n",
    "                    speaker = ref[1]\n",
    "                    sim = refexps.lex_sim(ref, refexps.get_previous(ref, refobj), language, splits)\n",
    "                    if sim != 'undefined':\n",
    "                        sim_align.append(sim)\n",
    "                        sim_align_speaker[speaker].append(sim)\n",
    "                sim_align = np.mean(sim_align)\n",
    "                comb_ref = combinations(refobj,2)\n",
    "                for comb in comb_ref:\n",
    "                    if comb[0] != comb[1]:\n",
    "                        sim = refexps.lex_sim(comb[0], comb[1], language, splits)\n",
    "                        if sim != 'undefined':\n",
    "                            sim_coherence.append(sim)\n",
    "                            sim_coherence_speaker[comb[0][1]].append(sim)\n",
    "                            sim_coherence_speaker[comb[1][1]].append(sim)\n",
    "                sim_coherence = np.mean(sim_coherence)\n",
    "                #movelevel coherence and alignment (for each object)\n",
    "                if not np.isnan(sim_coherence):\n",
    "                    move_level_coherence.append(sim_coherence)\n",
    "                if not np.isnan(sim_align):\n",
    "                    move_level_align.append(sim_align)\n",
    "                for s in sim_align_speaker:\n",
    "                    if not np.isnan(np.mean(sim_align_speaker[s])):\n",
    "                        playermove_level_align_speaker[s].append(np.mean(sim_align_speaker[s]))\n",
    "                for s in sim_coherence_speaker:\n",
    "                    if not np.isnan(np.mean(sim_coherence_speaker[s])) :\n",
    "                        playermove_level_coherence_speaker[s].append(np.mean(sim_coherence_speaker[s]))\n",
    "            values = [sim_coherence, sim_align, sim_align_speaker['e-utts'], sim_align_speaker['p-utts'], sim_coherence_speaker['e-utts'], sim_coherence_speaker['p-utts'] ]\n",
    "            move_level_data[move[0]]['values'] = values\n",
    "            success = success_moves[move[0]]\n",
    "            move_level_data[move[0]]['success'] = success\n",
    "    move_level_align_all = []\n",
    "    move_level_coherence_all = []\n",
    "\n",
    "    playermove_level_align_speaker_all = defaultdict(list)\n",
    "    playermove_level_coherence_speaker_all = defaultdict(list)\n",
    "\n",
    "    results_move = defaultdict(list)\n",
    "    \n",
    "    playermove_level_coherence = []\n",
    "    for s in playermove_level_coherence_speaker:\n",
    "        playermove_level_coherence += playermove_level_coherence_speaker[s]\n",
    "        playermove_level_coherence_speaker_all[s] += playermove_level_coherence_speaker[s]\n",
    "        results_move['Move coherence '+ s] = playermove_level_coherence_speaker[s]\n",
    "    results_move['Move players coherence'] = playermove_level_coherence\n",
    "    results_move['Move coherence'] = move_level_coherence\n",
    "\n",
    "    playermove_level_align = []\n",
    "    for s in playermove_level_align_speaker:\n",
    "        playermove_level_align += playermove_level_align_speaker[s]\n",
    "        playermove_level_align_speaker_all[s] += playermove_level_align_speaker[s]\n",
    "        results_move['Move alignment '+ s] = playermove_level_align_speaker[s]\n",
    "    results_move['Move players alignment'] = playermove_level_align\n",
    "    results_move['Move alignment'] = move_level_align\n",
    "\n",
    "    for value in results_move:\n",
    "        dataset = results_move[value]\n",
    "        print '\\t'+ value + ': '\n",
    "        print '\\tMean: '+ str(np.mean(dataset)) +'\\tStandard deviation: '+ str(np.std(dataset))\n",
    "        print '\\tMax value: ' + str(max(dataset)) + '\\tMin value: '+ str(min(dataset))\n",
    "    return results_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMove coherence: \n",
      "\tMean: 0.188896380461\tStandard deviation: 0.287182912161\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove alignment e-utts: \n",
      "\tMean: 0.0783389198412\tStandard deviation: 0.223947435992\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove alignment p-utts: \n",
      "\tMean: 0.0127828569427\tStandard deviation: 0.0914058853529\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove players coherence: \n",
      "\tMean: 0.173983654506\tStandard deviation: 0.282315728989\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove players alignment: \n",
      "\tMean: 0.0333440412273\tStandard deviation: 0.149631685608\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove coherence p-utts: \n",
      "\tMean: 0.178262116651\tStandard deviation: 0.279717995455\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove coherence e-utts: \n",
      "\tMean: 0.166282422645\tStandard deviation: 0.286771576991\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove alignment: \n",
      "\tMean: 0.0191384745641\tStandard deviation: 0.0830978312196\n",
      "\tMax value: 0.666666666667\tMin value: 0.0\n",
      "\n",
      "\n",
      "\n",
      "\tMove coherence: \n",
      "\tMean: 0.182823534546\tStandard deviation: 0.246655762255\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove alignment e-utts: \n",
      "\tMean: 0.0934812101479\tStandard deviation: 0.225846980243\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove alignment p-utts: \n",
      "\tMean: 0.0196791737528\tStandard deviation: 0.0938727685468\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove players coherence: \n",
      "\tMean: 0.169009761755\tStandard deviation: 0.239338265026\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove players alignment: \n",
      "\tMean: 0.0450012800819\tStandard deviation: 0.156579348053\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove coherence p-utts: \n",
      "\tMean: 0.186007752107\tStandard deviation: 0.2501683782\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove coherence e-utts: \n",
      "\tMean: 0.14396807954\tStandard deviation: 0.22004532393\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove alignment: \n",
      "\tMean: 0.0257054337089\tStandard deviation: 0.0848163529578\n",
      "\tMax value: 0.666666666667\tMin value: 0.0\n",
      "\n",
      "\n",
      "\n",
      "\tMove coherence: \n",
      "\tMean: 0.186897862078\tStandard deviation: 0.274521946312\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove alignment e-utts: \n",
      "\tMean: 0.0835496491526\tStandard deviation: 0.224718090937\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove alignment p-utts: \n",
      "\tMean: 0.0149524847032\tStandard deviation: 0.0922447041359\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove players coherence: \n",
      "\tMean: 0.172309573957\tStandard deviation: 0.268629727201\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove players alignment: \n",
      "\tMean: 0.0371226709321\tStandard deviation: 0.152016489776\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove coherence p-utts: \n",
      "\tMean: 0.180738918687\tStandard deviation: 0.270644245404\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove coherence e-utts: \n",
      "\tMean: 0.158141685095\tStandard deviation: 0.264605011675\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tMove alignment: \n",
      "\tMean: 0.0212946671422\tStandard deviation: 0.083722798893\n",
      "\tMax value: 0.666666666667\tMin value: 0.0\n"
     ]
    }
   ],
   "source": [
    "de_dataset_dir = 'En_De_Dataset/De/RefExp'\n",
    "de_success_dir = 'En_De_Dataset/De/Success'\n",
    "\n",
    "en_dataset_dir = 'En_De_Dataset/En/RefExp'\n",
    "en_success_dir = 'En_De_Dataset/En/Success'\n",
    "\n",
    "all_dataset_dir = 'En_De_Dataset/All/RefExp'\n",
    "all_success_dir = 'En_De_Dataset/All/Success'\n",
    "\n",
    "results_de = compute_values_move(de_dataset_dir, de_success_dir)\n",
    "print '\\n\\n'\n",
    "results_en = compute_values_move(en_dataset_dir, en_success_dir)\n",
    "print '\\n\\n'\n",
    "results_all = compute_values_move(all_dataset_dir, all_success_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move coherence\n",
      " Not significantly different\n",
      "Move alignment e-utts\n",
      " Not significantly different\n",
      "Move alignment p-utts\n",
      " Not significantly different\n",
      "Move players coherence\n",
      " Not significantly different\n",
      "Move players alignment\n",
      " Not significantly different\n",
      "Move coherence p-utts\n",
      " Not significantly different\n",
      "Move coherence e-utts\n",
      " Not significantly different\n",
      "Move alignment\n",
      " Not significantly different\n"
     ]
    }
   ],
   "source": [
    "for var in results_all:\n",
    "    print var\n",
    "    ttest =  stats.ttest_ind(results_de[var],results_en[var])\n",
    "    if ttest[1] < 0.05:\n",
    "        print str(ttest)+'\\tSignificantly different'\n",
    "    else:\n",
    "        print ' Not significantly different'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_values_game(refexps_dir, success_dir):\n",
    "    splits = compound_splitter.load_dict('de_lower.dict')\n",
    "    game_level_align = []\n",
    "    game_level_coherence = []\n",
    "    playergame_level_align_speaker = defaultdict(list)\n",
    "    playergame_level_coherence_speaker = defaultdict(list)\n",
    "\n",
    "    for dialogue in listdir(refexps_dir):\n",
    "        if dialogue.startswith('FTT'):\n",
    "            language = 'german'\n",
    "        else:\n",
    "            language = 'english'\n",
    "        dialogue = refexps.load_data(path.join(refexps_dir, dialogue))\n",
    "        dialogue_game = refexps.gamerun_level(dialogue)\n",
    "        for obj in dialogue_game:\n",
    "            refobj = dialogue_game[obj]\n",
    "            sim_align = []\n",
    "            sim_align_speaker = defaultdict(list)\n",
    "            sim_coherence_speaker = defaultdict(list)\n",
    "            sim_coherence = []\n",
    "            for ref in refobj:\n",
    "                speaker = ref[1]\n",
    "                sim = refexps.lex_sim(ref, refexps.get_previous(ref, refobj), language, splits)\n",
    "                if sim != 'undefined':\n",
    "                    sim_align.append(sim)\n",
    "                    sim_align_speaker[speaker].append(sim)\n",
    "            sim_align = np.mean(sim_align)\n",
    "            for s in sim_align_speaker[speaker]:\n",
    "                sim_align_speaker[speaker] = np.mean(sim_align_speaker[speaker])\n",
    "            comb_ref = combinations(refobj,2)\n",
    "            for comb in comb_ref:\n",
    "                if comb[0] != comb[1]:\n",
    "                    sim = refexps.lex_sim(comb[0], comb[1], language, splits)\n",
    "                    if sim != 'undefined':\n",
    "                        sim_coherence.append(sim)\n",
    "                        sim_coherence_speaker[comb[0][1]].append(sim)\n",
    "                        sim_coherence_speaker[comb[1][1]].append(sim)\n",
    "            sim_coherence = np.mean(sim_coherence)\n",
    "            #gamelevel coherence and alignment (for each object)\n",
    "            if not np.isnan(sim_coherence) :\n",
    "                game_level_coherence.append(sim_coherence)\n",
    "            if not np.isnan(sim_align):\n",
    "                game_level_align.append(sim_align)\n",
    "            for s in sim_align_speaker:\n",
    "                if not np.isnan(np.mean(sim_align_speaker[s])):\n",
    "                    playergame_level_align_speaker[s].append(np.mean(sim_align_speaker[s]))\n",
    "            for s in sim_coherence_speaker:\n",
    "                if not np.isnan(np.mean(sim_coherence_speaker[s])) :\n",
    "                    playergame_level_coherence_speaker[s].append(np.mean(sim_coherence_speaker[s]))\n",
    "\n",
    "    game_level_align_all = []\n",
    "    game_level_coherence_all = []\n",
    "\n",
    "    playergame_level_align_speaker_all = defaultdict(list)\n",
    "    playergame_level_coherence_speaker_all = defaultdict(list)\n",
    "\n",
    "    results_game = defaultdict(list)\n",
    "\n",
    "    playergame_level_coherence = []\n",
    "    for s in playergame_level_coherence_speaker:\n",
    "        playergame_level_coherence += playergame_level_coherence_speaker[s]\n",
    "        playergame_level_coherence_speaker_all[s] += playergame_level_coherence_speaker[s]\n",
    "        results_game['game coherence '+ s] = playergame_level_coherence_speaker[s]\n",
    "    results_game['game players coherence'] = playergame_level_coherence\n",
    "    results_game['game coherence'] = game_level_coherence\n",
    "    playergame_level_align = []\n",
    "    for s in playergame_level_align_speaker:\n",
    "        playergame_level_align += playergame_level_align_speaker[s]\n",
    "        playergame_level_align_speaker_all[s] += playergame_level_align_speaker[s]\n",
    "        results_game['game alignment '+ s] = playergame_level_align_speaker[s]\n",
    "    results_game['game players alignment'] = playergame_level_align\n",
    "    results_game['game alignment'] = game_level_align\n",
    "    for value in results_game:\n",
    "        dataset = results_game[value]\n",
    "        print '\\t'+ value + ': '\n",
    "        print '\\tMean: '+ str(np.mean(dataset)) +'\\tStandard deviation: '+ str(np.std(dataset))\n",
    "        print '\\tMax value: ' + str(max(dataset)) + '\\tMin value: '+ str(min(dataset))\n",
    "    return results_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgame players coherence: \n",
      "\tMean: 0.111700272806\tStandard deviation: 0.173066823379\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tgame coherence e-utts: \n",
      "\tMean: 0.113244535277\tStandard deviation: 0.172929050429\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tgame alignment: \n",
      "\tMean: 0.0193176036799\tStandard deviation: 0.0696030133704\n",
      "\tMax value: 0.533333333333\tMin value: 0.0\n",
      "\tgame alignment p-utts: \n",
      "\tMean: 0.0106359878023\tStandard deviation: 0.0496096345117\n",
      "\tMax value: 0.5\tMin value: 0.0\n",
      "\tgame coherence p-utts: \n",
      "\tMean: 0.110818877717\tStandard deviation: 0.173139234795\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tgame players alignment: \n",
      "\tMean: 0.0337033816161\tStandard deviation: 0.128962167906\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tgame coherence: \n",
      "\tMean: 0.114203590182\tStandard deviation: 0.175171250337\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tgame alignment e-utts: \n",
      "\tMean: 0.08114036083\tStandard deviation: 0.205977917528\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\n",
      "\n",
      "\n",
      "\tgame players coherence: \n",
      "\tMean: 0.143861468595\tStandard deviation: 0.196350067651\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tgame coherence e-utts: \n",
      "\tMean: 0.121505668035\tStandard deviation: 0.181182455022\n",
      "\tMax value: 0.857142857143\tMin value: 0.0\n",
      "\tgame alignment: \n",
      "\tMean: 0.0294604775775\tStandard deviation: 0.0801600540936\n",
      "\tMax value: 0.555555555556\tMin value: 0.0\n",
      "\tgame alignment p-utts: \n",
      "\tMean: 0.0194201720518\tStandard deviation: 0.0749438558093\n",
      "\tMax value: 0.6\tMin value: 0.0\n",
      "\tgame coherence p-utts: \n",
      "\tMean: 0.159427729726\tStandard deviation: 0.204817535617\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tgame players alignment: \n",
      "\tMean: 0.050421674357\tStandard deviation: 0.1474382102\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tgame coherence: \n",
      "\tMean: 0.163800403276\tStandard deviation: 0.207632708866\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tgame alignment e-utts: \n",
      "\tMean: 0.101401922592\tStandard deviation: 0.20992711915\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\n",
      "\n",
      "\n",
      "\tgame players coherence: \n",
      "\tMean: 0.124805101695\tStandard deviation: 0.183593640616\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tgame coherence e-utts: \n",
      "\tMean: 0.116856379367\tStandard deviation: 0.176632522642\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tgame alignment: \n",
      "\tMean: 0.0232659951506\tStandard deviation: 0.0740574547055\n",
      "\tMax value: 0.555555555556\tMin value: 0.0\n",
      "\tgame alignment p-utts: \n",
      "\tMean: 0.0138619413232\tStandard deviation: 0.0603148199168\n",
      "\tMax value: 0.6\tMin value: 0.0\n",
      "\tgame coherence p-utts: \n",
      "\tMean: 0.129730102562\tStandard deviation: 0.187608389211\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tgame players alignment: \n",
      "\tMean: 0.0401522530462\tStandard deviation: 0.136628493099\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tgame coherence: \n",
      "\tMean: 0.134070100749\tStandard deviation: 0.190402509981\n",
      "\tMax value: 1.0\tMin value: 0.0\n",
      "\tgame alignment e-utts: \n",
      "\tMean: 0.0896615783936\tStandard deviation: 0.207888702327\n",
      "\tMax value: 1.0\tMin value: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_de = compute_values_game(de_dataset_dir, de_success_dir)\n",
    "print '\\n\\n'\n",
    "results_en = compute_values_game(en_dataset_dir, en_success_dir)\n",
    "print '\\n\\n'\n",
    "results_all = compute_values_game(all_dataset_dir, all_success_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game players coherence\n",
      "Ttest_indResult(statistic=-2.0444991328327111, pvalue=0.041371339619496031)\tSignificantly different\n",
      "game coherence e-utts\n",
      " Not significantly different\n",
      "game alignment\n",
      " Not significantly different\n",
      "game alignment p-utts\n",
      " Not significantly different\n",
      "game coherence p-utts\n",
      "Ttest_indResult(statistic=-2.3652161885405674, pvalue=0.018572248905435813)\tSignificantly different\n",
      "game players alignment\n",
      " Not significantly different\n",
      "game coherence\n",
      "Ttest_indResult(statistic=-2.4247606529011838, pvalue=0.015816939112154101)\tSignificantly different\n",
      "game alignment e-utts\n",
      " Not significantly different\n"
     ]
    }
   ],
   "source": [
    "for var in results_all:\n",
    "    print var\n",
    "    ttest =  stats.ttest_ind(results_de[var],results_en[var])\n",
    "    if ttest[1] < 0.05:\n",
    "        print str(ttest)+'\\tSignificantly different'\n",
    "    else:\n",
    "        print ' Not significantly different'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "game players coherence and game coherence is always significantly higher at the move level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'Dataset/Disruption_with_Noise_Corpus/Success/20070201_run1pento_nonoise_success.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7a14c5568cab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrefexps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dataset/Disruption_with_Noise_Corpus/Success/20070201_run1pento_nonoise_success.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'Dataset/Disruption_with_Noise_Corpus/Success/20070201_run1pento_nonoise_success.p'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "refexps = pickle.load(open('Dataset/Disruption_with_Noise_Corpus/Success/20070201_run1pento_nonoise_success.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((4, 251),\n",
       "  {'e-utts': {'1l': {'location': [('a short bit', (61, 63), 'indef_np'),\n",
       "      ('the short bit', (70, 72), 'def_np'),\n",
       "      ('a block of four', (224, 227), 'indef_np')],\n",
       "     'part_of_piece': [('a short bit', (61, 63), 'indef_np'),\n",
       "      ('the short bit', (70, 72), 'def_np'),\n",
       "      ('a block of four', (224, 227), 'indef_np')],\n",
       "     'piece': [('a short bit', (61, 63), 'indef_np'),\n",
       "      ('the short bit', (70, 72), 'def_np'),\n",
       "      ('a block of four', (224, 227), 'indef_np')]}},\n",
       "   'p-utts': {'1l': {'desc_piece': [('the short l bottom bit',\n",
       "       (29, 33),\n",
       "       'def_np'),\n",
       "      ('two squares', (36, 37), 'quant_np'),\n",
       "      ('the short bit', (44, 46), 'def_np')],\n",
       "     'location': [('the short l bottom bit', (29, 33), 'def_np'),\n",
       "      ('two squares', (36, 37), 'quant_np'),\n",
       "      ('the short bit', (44, 46), 'def_np')],\n",
       "     'part_of_piece': [('the short l bottom bit', (29, 33), 'def_np'),\n",
       "      ('two squares', (36, 37), 'quant_np'),\n",
       "      ('the short bit', (44, 46), 'def_np')],\n",
       "     'piece': [('the short l bottom bit', (29, 33), 'def_np'),\n",
       "      ('two squares', (36, 37), 'quant_np'),\n",
       "      ('the short bit', (44, 46), 'def_np')]}}}),\n",
       " ((252, 595),\n",
       "  {'e-utts': {'0z': {'piece': [('it', (502, 502), 'pronoun'),\n",
       "      ('it', (453, 453), 'pronoun'),\n",
       "      ('it', (556, 556), 'pronoun'),\n",
       "      ('it', (515, 515), 'pronoun')]},\n",
       "    '2n': {'part_of_piece': [('it', (299, 299), 'pronoun'),\n",
       "      ('it', (381, 381), 'pronoun'),\n",
       "      ('it', (500, 500), 'pronoun'),\n",
       "      ('it', (510, 510), 'pronoun')],\n",
       "     'piece': [('it', (299, 299), 'pronoun'),\n",
       "      ('it', (381, 381), 'pronoun'),\n",
       "      ('it', (500, 500), 'pronoun'),\n",
       "      ('it', (510, 510), 'pronoun')]}},\n",
       "   'p-utts': {'0z': {'location': [('on the  left hand side',\n",
       "       (459, 464),\n",
       "       'pp')],\n",
       "     'part_of_piece': [('the  four block bit', (478, 482), 'def_np'),\n",
       "      ('the block of four', (528, 531), 'def_np')],\n",
       "     'piece': [('it', (548, 548), 'pronoun'),\n",
       "      ('your block that you had s- originally on the screen',\n",
       "       (439, 448),\n",
       "       'def_np'),\n",
       "      ('it', (495, 495), 'pronoun')]},\n",
       "    '1l': {'piece': [('the other one', (326, 328), 'def_np')]},\n",
       "    '2n': {'comp_piece': [('the same sort of shape as the other one',\n",
       "       (320, 328),\n",
       "       'def_np')],\n",
       "     'desc_piece': [(\"it's the same sort of shape as the other one\",\n",
       "       (319, 328),\n",
       "       'other_sent'),\n",
       "      (\"it's just got an extra bit\", (329, 334), 'attribution_sent')],\n",
       "     'location': [('into  four block bit', (467, 482), 'pp'),\n",
       "      ('on the left hand side of it', (489, 495), 'pp')],\n",
       "     'part_of_piece': [('an extra bit', (315, 317), 'indef_np'),\n",
       "      ('the two', (421, 422), 'def_np'),\n",
       "      ('an extra bit', (332, 334), 'indef_np'),\n",
       "      ('a length of three blocks', (349, 353), 'indef_np'),\n",
       "      ('a length of two', (271, 274), 'indef_np'),\n",
       "      ('two tagged on to the end', (363, 368), 'quant_np'),\n",
       "      ('the three', (403, 404), 'def_np'),\n",
       "      ('the three', (389, 390), 'def_np')],\n",
       "     'piece': [('that', (413, 413), 'def_np'),\n",
       "      ('it', (329, 329), 'pronoun'),\n",
       "      ('it', (280, 280), 'pronoun'),\n",
       "      ('it', (506, 506), 'pronoun'),\n",
       "      ('it', (504, 504), 'pronoun'),\n",
       "      ('it', (261, 261), 'pronoun'),\n",
       "      ('n:ext one', (255, 256), 'def_np'),\n",
       "      ('an l with an extra bit', (312, 317), 'indef_np'),\n",
       "      ('that', (589, 589), 'def_np'),\n",
       "      ('it', (385, 385), 'pronoun'),\n",
       "      ('it', (319, 319), 'pronoun')]}}}),\n",
       " ((596, 657),\n",
       "  {'e-utts': {'3v': {'piece': [('that one', (634, 635), 'def_np')]}},\n",
       "   'p-utts': {'2n': {'piece': [('the one i meant', (648, 651), 'def_np')]},\n",
       "    '3v': {'piece': [('next one', (598, 599), 'def_np'),\n",
       "      ('another   l shape', (604, 608), 'indef_np'),\n",
       "      ('it', (610, 610), 'pronoun'),\n",
       "      ('it', (614, 614), 'pronoun'),\n",
       "      ('that`s', (629, 629), 'def_np'),\n",
       "      ('that one', (640, 641), 'def_np')]}}}),\n",
       " ((658, 1315),\n",
       "  {'e-utts': {'0z': {'desc_piece': [(\"it's like a three bit and then there's one on top on one end an one on top of  the other end   on at the bottom\",\n",
       "       (976, 1004),\n",
       "       'attribution_sent')],\n",
       "     'part_of_piece': [('the two of the one that was already there',\n",
       "       (1296, 1304),\n",
       "       'def_np')],\n",
       "     'piece': [('it', (976, 976), 'pronoun'),\n",
       "      ('the one that was originally there', (950, 955), 'def_np'),\n",
       "      ('this one that was originally there', (960, 965), 'def_np'),\n",
       "      ('a three by one', (970, 973), 'indef_np'),\n",
       "      ('the one that was already there', (1299, 1304), 'def_np')]},\n",
       "    '1l': {'location': [('in the bottom right hand corner',\n",
       "       (1126, 1131),\n",
       "       'pp')],\n",
       "     'part_of_piece': [('in the bottom right hand corner',\n",
       "       (1126, 1131),\n",
       "       'pp')],\n",
       "     'piece': [('in the bottom right hand corner', (1126, 1131), 'pp')]},\n",
       "    '2n': {'part_of_piece': [('they', (1293, 1293), 'pronoun'),\n",
       "      ('the three', (1291, 1292), 'def_np'),\n",
       "      ('the two that are going up', (1276, 1281), 'def_np')]},\n",
       "    '3v': {'comp_piece': [('an l', (737, 738), 'indef_np')],\n",
       "     'part_of_piece': [('on the top one', (831, 834), 'indef_np'),\n",
       "      ('a block of two', (847, 850), 'indef_np'),\n",
       "      ('a block of three', (825, 828), 'indef_np')],\n",
       "     'piece': [('that', (1096, 1096), 'def_np'),\n",
       "      ('it', (1014, 1014), 'pronoun'),\n",
       "      ('it', (820, 820), 'pronoun'),\n",
       "      ('one', (1088, 1088), 'indef_np'),\n",
       "      ('that', (900, 900), 'def_np'),\n",
       "      ('it', (823, 823), 'pronoun'),\n",
       "      ('symmetrical l  thing', (1024, 1027), 'indef_np'),\n",
       "      ('this', (1053, 1053), 'pronoun'),\n",
       "      ('it', (761, 761), 'pronoun'),\n",
       "      ('it', (734, 734), 'pronoun'),\n",
       "      ('it', (743, 743), 'pronoun')]}},\n",
       "   'p-utts': {'0z': {'part_of_piece': [('the block of  kind',\n",
       "       (1228, 1232),\n",
       "       'def_np'),\n",
       "      ('the block of four', (1214, 1217), 'def_np'),\n",
       "      ('block of four', (1249, 1251), 'def_np'),\n",
       "      ('the four', (1261, 1262), 'def_np')],\n",
       "     'piece': [('the one that was originally there', (933, 938), 'def_np'),\n",
       "      ('the one that was originally there', (920, 925), 'def_np')]},\n",
       "    '1l': {'piece': [('the one we put in', (927, 931), 'def_np'),\n",
       "      ('the first ! one', (1097, 1100), 'def_np'),\n",
       "      (\"the one that's not symmetrical l\", (1101, 1106), 'def_np')]},\n",
       "    '2n': {'part_of_piece': [('the length of   two', (1158, 1163), 'def_np'),\n",
       "      ('the two', (1189, 1190), 'def_np'),\n",
       "      ('the three', (1167, 1168), 'def_np'),\n",
       "      ('the lenght of three', (1153, 1156), 'def_np')],\n",
       "     'piece': [('the lenght of three with the length of   two',\n",
       "       (1153, 1163),\n",
       "       'def_np'),\n",
       "      ('the next one', (1147, 1149), 'def_np')]},\n",
       "    '3v': {'location': [('to the left', (1197, 1199), 'pp'),\n",
       "      ('in the space   u:hm to the: left hand side of the one that was originally there',\n",
       "       (908, 925),\n",
       "       'pp')],\n",
       "     'part_of_piece': [('the block of two', (882, 885), 'def_np'),\n",
       "      ('the block of three', (864, 867), 'def_np'),\n",
       "      ('the block of three', (893, 896), 'def_np'),\n",
       "      ('the block of two', (874, 877), 'def_np'),\n",
       "      (\"they're\", (809, 809), 'pronoun'),\n",
       "      ('a block of three', (668, 671), 'indef_np'),\n",
       "      ('two  blocks', (784, 786), 'quant_np'),\n",
       "      ('a block of two', (689, 692), 'indef_np'),\n",
       "      ('it', (720, 720), 'pronoun'),\n",
       "      ('a length of three  blocks', (768, 773), 'indef_np')],\n",
       "     'piece': [('the symmetrical l thing', (1058, 1061), 'def_np'),\n",
       "      ('it', (1254, 1254), 'pronoun'),\n",
       "      ('it', (660, 660), 'pronoun'),\n",
       "      ('symmetrical l', (1105, 1106), 'def_np'),\n",
       "      ('that', (860, 860), 'def_np'),\n",
       "      ('it', (749, 749), 'pronoun'),\n",
       "      ('the next one', (1311, 1313), 'def_np'),\n",
       "      ('it', (1044, 1044), 'pronoun'),\n",
       "      ('that', (903, 903), 'def_np'),\n",
       "      ('it', (717, 717), 'pronoun'),\n",
       "      ('it', (1034, 1034), 'pronoun'),\n",
       "      ('it', (699, 699), 'pronoun'),\n",
       "      ('symmetrical l thing', (1028, 1030), 'indef_np'),\n",
       "      ('it', (730, 730), 'pronoun'),\n",
       "      ('that', (1195, 1195), 'def_np')]}}}),\n",
       " ((1316, 1491),\n",
       "  {'e-utts': {'3v': {'desc_piece': [(\"it's got three up and then  two across\",\n",
       "       (1415, 1423),\n",
       "       'attribution_sent')],\n",
       "     'part_of_piece': [(\"it's got three up and then  two across\",\n",
       "       (1415, 1423),\n",
       "       'attribution_sent')],\n",
       "     'piece': [(\"it's got three up and then  two across\",\n",
       "       (1415, 1423),\n",
       "       'attribution_sent')]}},\n",
       "   'p-utts': {'3v': {'location': [('at the bottom', (1360, 1362), 'pp'),\n",
       "      ('on the f:ar left hand of the grid', (1453, 1460), 'pp'),\n",
       "      ('a  space', (1463, 1465), 'indef_np')],\n",
       "     'part_of_piece': [('at the bottom', (1360, 1362), 'pp'),\n",
       "      ('on the f:ar left hand of the grid', (1453, 1460), 'pp'),\n",
       "      ('a  space', (1463, 1465), 'indef_np')],\n",
       "     'piece': [('at the bottom', (1360, 1362), 'pp'),\n",
       "      ('on the f:ar left hand of the grid', (1453, 1460), 'pp'),\n",
       "      ('a  space', (1463, 1465), 'indef_np')]}}}),\n",
       " ((1492, 1559),\n",
       "  {'e-utts': {'4t': {'piece': [('that', (1502, 1502), 'def_np'),\n",
       "      ('it', (1536, 1536), 'pronoun'),\n",
       "      ('this t', (1540, 1541), 'def_np'),\n",
       "      ('its', (1543, 1543), 'pronoun')]}},\n",
       "   'p-utts': {'0z': {'piece': [('the one that was already there#',\n",
       "       (1520, 1525),\n",
       "       'def_np')]},\n",
       "    '1l': {'piece': [('our first one', (1516, 1518), 'def_np')]},\n",
       "    '4t': {'location': [('whe:re  we had our first one', (1512, 1518), 'pp')],\n",
       "     'piece': [('the next one', (1492, 1494), 'def_np'),\n",
       "      ('a t', (1498, 1499), 'indef_np'),\n",
       "      ('that', (1507, 1507), 'def_np')]},\n",
       "    '5y': {'piece': [('the next one', (1556, 1558), 'def_np')]}}}),\n",
       " ((1560, 1785),\n",
       "  {'e-utts': {'5y': {'location': [('one jutting out',\n",
       "       (1574, 1576),\n",
       "       'quant_np')],\n",
       "     'part_of_piece': [('one jutting out', (1574, 1576), 'quant_np')],\n",
       "     'piece': [('one jutting out', (1574, 1576), 'quant_np')]}},\n",
       "   'p-utts': {'5y': {'location': [('it', (1585, 1585), 'pronoun'),\n",
       "      ('it', (1589, 1589), 'pronoun'),\n",
       "      ('that', (1613, 1613), 'def_np'),\n",
       "      ('it', (1618, 1618), 'pronoun'),\n",
       "      ('that', (1667, 1667), 'def_np'),\n",
       "      ('it', (1689, 1689), 'pronoun'),\n",
       "      ('to uh    next level kind of thing', (1694, 1704), 'pp'),\n",
       "      ('it', (1737, 1737), 'pronoun'),\n",
       "      ('it', (1778, 1778), 'pronoun')],\n",
       "     'part_of_piece': [('it', (1585, 1585), 'pronoun'),\n",
       "      ('it', (1589, 1589), 'pronoun'),\n",
       "      ('that', (1613, 1613), 'def_np'),\n",
       "      ('it', (1618, 1618), 'pronoun'),\n",
       "      ('that', (1667, 1667), 'def_np'),\n",
       "      ('it', (1689, 1689), 'pronoun'),\n",
       "      ('to uh    next level kind of thing', (1694, 1704), 'pp'),\n",
       "      ('it', (1737, 1737), 'pronoun'),\n",
       "      ('it', (1778, 1778), 'pronoun')],\n",
       "     'piece': [('it', (1585, 1585), 'pronoun'),\n",
       "      ('it', (1589, 1589), 'pronoun'),\n",
       "      ('that', (1613, 1613), 'def_np'),\n",
       "      ('it', (1618, 1618), 'pronoun'),\n",
       "      ('that', (1667, 1667), 'def_np'),\n",
       "      ('it', (1689, 1689), 'pronoun'),\n",
       "      ('to uh    next level kind of thing', (1694, 1704), 'pp'),\n",
       "      ('it', (1737, 1737), 'pronoun'),\n",
       "      ('it', (1778, 1778), 'pronoun')]}}}),\n",
       " ((1786, 2114),\n",
       "  {'e-utts': {'6w': {'part_of_piece': [('it', (1900, 1900), 'pronoun'),\n",
       "      ('this', (1999, 1999), 'pronoun'),\n",
       "      ('it', (2017, 2017), 'pronoun'),\n",
       "      ('that', (2022, 2022), 'def_np'),\n",
       "      ('it', (2029, 2029), 'pronoun'),\n",
       "      ('it', (2039, 2039), 'pronoun'),\n",
       "      ('an l', (2041, 2042), 'indef_np')],\n",
       "     'piece': [('it', (1900, 1900), 'pronoun'),\n",
       "      ('this', (1999, 1999), 'pronoun'),\n",
       "      ('it', (2017, 2017), 'pronoun'),\n",
       "      ('that', (2022, 2022), 'def_np'),\n",
       "      ('it', (2029, 2029), 'pronoun'),\n",
       "      ('it', (2039, 2039), 'pronoun'),\n",
       "      ('an l', (2041, 2042), 'indef_np')]}},\n",
       "   'p-utts': {'0z': {'location': [('on the right hand side of the screen',\n",
       "       (2092, 2099),\n",
       "       'pp')],\n",
       "     'piece': [('the original one', (2075, 2077), 'def_np'),\n",
       "      ('the one that was originally there', (2086, 2091), 'def_np')]},\n",
       "    '3v': {'part_of_piece': [('the back of it', (1961, 1964), 'def_np')],\n",
       "     'piece': [('it', (1964, 1964), 'pronoun'),\n",
       "      ('the symmetrical   l  that we had before', (1944, 1953), 'def_np')]},\n",
       "    '6w': {'comp_piece': [('a block of three', (1796, 1799), 'indef_np'),\n",
       "      ('one tagged on  to the edge', (1803, 1809), 'quant_np'),\n",
       "      ('another two blocks', (1820, 1822), 'indef_np'),\n",
       "      ('two blocks', (1844, 1845), 'quant_np'),\n",
       "      ('those two blocks', (1854, 1856), 'def_np'),\n",
       "      ('another  block', (1862, 1864), 'indef_np'),\n",
       "      ('that block', (1881, 1882), 'def_np'),\n",
       "      (\"one block that's been taken out\", (1987, 1992), 'quant_np'),\n",
       "      ('it', (1994, 1994), 'pronoun')],\n",
       "     'desc_piece': [('a block of three', (1796, 1799), 'indef_np'),\n",
       "      ('one tagged on  to the edge', (1803, 1809), 'quant_np'),\n",
       "      ('another two blocks', (1820, 1822), 'indef_np'),\n",
       "      ('two blocks', (1844, 1845), 'quant_np'),\n",
       "      ('those two blocks', (1854, 1856), 'def_np'),\n",
       "      ('another  block', (1862, 1864), 'indef_np'),\n",
       "      ('that block', (1881, 1882), 'def_np'),\n",
       "      (\"one block that's been taken out\", (1987, 1992), 'quant_np'),\n",
       "      ('it', (1994, 1994), 'pronoun')],\n",
       "     'location': [('a block of three', (1796, 1799), 'indef_np'),\n",
       "      ('one tagged on  to the edge', (1803, 1809), 'quant_np'),\n",
       "      ('another two blocks', (1820, 1822), 'indef_np'),\n",
       "      ('two blocks', (1844, 1845), 'quant_np'),\n",
       "      ('those two blocks', (1854, 1856), 'def_np'),\n",
       "      ('another  block', (1862, 1864), 'indef_np'),\n",
       "      ('that block', (1881, 1882), 'def_np'),\n",
       "      (\"one block that's been taken out\", (1987, 1992), 'quant_np'),\n",
       "      ('it', (1994, 1994), 'pronoun')],\n",
       "     'part_of_piece': [('a block of three', (1796, 1799), 'indef_np'),\n",
       "      ('one tagged on  to the edge', (1803, 1809), 'quant_np'),\n",
       "      ('another two blocks', (1820, 1822), 'indef_np'),\n",
       "      ('two blocks', (1844, 1845), 'quant_np'),\n",
       "      ('those two blocks', (1854, 1856), 'def_np'),\n",
       "      ('another  block', (1862, 1864), 'indef_np'),\n",
       "      ('that block', (1881, 1882), 'def_np'),\n",
       "      (\"one block that's been taken out\", (1987, 1992), 'quant_np'),\n",
       "      ('it', (1994, 1994), 'pronoun')],\n",
       "     'piece': [('a block of three', (1796, 1799), 'indef_np'),\n",
       "      ('one tagged on  to the edge', (1803, 1809), 'quant_np'),\n",
       "      ('another two blocks', (1820, 1822), 'indef_np'),\n",
       "      ('two blocks', (1844, 1845), 'quant_np'),\n",
       "      ('those two blocks', (1854, 1856), 'def_np'),\n",
       "      ('another  block', (1862, 1864), 'indef_np'),\n",
       "      ('that block', (1881, 1882), 'def_np'),\n",
       "      (\"one block that's been taken out\", (1987, 1992), 'quant_np'),\n",
       "      ('it', (1994, 1994), 'pronoun')]},\n",
       "    '7x': {'piece': [('the next one', (2108, 2110), 'def_np')]}}}),\n",
       " ((2115, 2406),\n",
       "  {'e-utts': {'5y': {'part_of_piece': [('the side of it',\n",
       "       (2196, 2199),\n",
       "       'def_np')],\n",
       "     'piece': [('it', (2181, 2181), 'pronoun'),\n",
       "      ('it', (2199, 2199), 'pronoun')]},\n",
       "    '7x': {'location': [('on top ! of it ?', (2177, 2182), 'pp')],\n",
       "     'piece': [('on top ! of it ?', (2177, 2182), 'pp')]}},\n",
       "   'p-utts': {'5y': {'part_of_piece': [('the length', (2164, 2165), 'def_np'),\n",
       "      ('the   uh the bit down', (2167, 2173), 'def_np'),\n",
       "      ('the side of it', (2202, 2205), 'def_np')],\n",
       "     'piece': [('it', (2205, 2205), 'pronoun'),\n",
       "      ('the one   we had before', (2154, 2160), 'def_np')]},\n",
       "    '7x': {'location': [('up in  the   left hand side of the screen',\n",
       "       (2127, 2138),\n",
       "       'pp'),\n",
       "      ('a bit where it kind of jumps out', (2141, 2148), 'indef_np'),\n",
       "      ('on top of the one   we had before', (2151, 2160), 'pp'),\n",
       "      ('to the side of it', (2201, 2205), 'pp'),\n",
       "      ('the second block down from the top', (2239, 2245), 'def_np')],\n",
       "     'piece': [('up in  the   left hand side of the screen',\n",
       "       (2127, 2138),\n",
       "       'pp'),\n",
       "      ('a bit where it kind of jumps out', (2141, 2148), 'indef_np'),\n",
       "      ('on top of the one   we had before', (2151, 2160), 'pp'),\n",
       "      ('to the side of it', (2201, 2205), 'pp'),\n",
       "      ('the second block down from the top', (2239, 2245), 'def_np')]},\n",
       "    '8f': {'piece': [('the next one', (2402, 2404), 'def_np')]}}}),\n",
       " ((2407, 2542),\n",
       "  {'e-utts': {'5y': {'part_of_piece': [(' blocks', (2521, 2524), 'quant_np'),\n",
       "      ('one sticking below', (2527, 2529), 'quant_np')],\n",
       "     'piece': [(' blocks', (2521, 2524), 'quant_np'),\n",
       "      ('one sticking below', (2527, 2529), 'quant_np')]},\n",
       "    '8f': {'location': [('below  blocks and the one sticking below',\n",
       "       (2514, 2529),\n",
       "       'pp')],\n",
       "     'piece': [('it', (2433, 2433), 'pronoun'),\n",
       "      ('it', (2513, 2513), 'pronoun'),\n",
       "      ('it', (2437, 2437), 'pronoun'),\n",
       "      ('it', (2508, 2508), 'pronoun')]}},\n",
       "   'p-utts': {'8f': {'desc_piece': [('the long side', (2416, 2418), 'def_np'),\n",
       "      ('a block out', (2427, 2429), 'indef_np'),\n",
       "      ('the l', (2443, 2444), 'def_np'),\n",
       "      ('the long side', (2452, 2454), 'def_np'),\n",
       "      ('the  short side', (2459, 2462), 'def_np'),\n",
       "      ('the block out', (2480, 2482), 'def_np')],\n",
       "     'part_of_piece': [('the long side', (2416, 2418), 'def_np'),\n",
       "      ('a block out', (2427, 2429), 'indef_np'),\n",
       "      ('the l', (2443, 2444), 'def_np'),\n",
       "      ('the long side', (2452, 2454), 'def_np'),\n",
       "      ('the  short side', (2459, 2462), 'def_np'),\n",
       "      ('the block out', (2480, 2482), 'def_np')]},\n",
       "    '9c': {'piece': [('the next one', (2538, 2540), 'def_np')]}}}),\n",
       " ((2543, 2563),\n",
       "  {'e-utts': {'9c': {'location': [('this', (2557, 2557), 'def_np')],\n",
       "     'piece': [('this', (2557, 2557), 'def_np')]}},\n",
       "   'p-utts': {'9c': {'location': [('top left', (2561, 2562), 'pp')],\n",
       "     'piece': [('top left', (2561, 2562), 'pp')]}}}),\n",
       " ((2564, 2592),\n",
       "  {'e-utts': {'10p': {'piece': [('that', (2586, 2586), 'def_np')]}},\n",
       "   'p-utts': {'10p': {'part_of_piece': [('block floor',\n",
       "       (2569, 2570),\n",
       "       'indef_np'),\n",
       "      ('a block', (2575, 2576), 'indef_np'),\n",
       "      ('one on top', (2577, 2579), 'quant_np')],\n",
       "     'piece': [('block floor', (2569, 2570), 'indef_np'),\n",
       "      ('a block', (2575, 2576), 'indef_np'),\n",
       "      ('one on top', (2577, 2579), 'quant_np')]}}}),\n",
       " ((2593, 2616),\n",
       "  {'e-utts': {'11i': {'piece': [('last one:', (2605, 2606), 'def_np')]}},\n",
       "   'p-utts': {'11i': {'piece': [('the last one', (2595, 2597), 'def_np'),\n",
       "      ('the  long', (2599, 2604), 'def_np')]}}})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refexps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
