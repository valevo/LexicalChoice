{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "from os import path, listdir, makedirs, stat\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "def extract_info(dialogue):\n",
    "    words_tree = ET.parse(path.join(basedata, dialogue + '_words.xml'))\n",
    "    words_root = words_tree.getroot()\n",
    "    words = {}\n",
    "    for word in words_root:\n",
    "        words[int(word.attrib['id'].strip('word_'))] = word.text\n",
    "    #moves\n",
    "    moves_tree = ET.parse(path.join(markables, dialogue + '_move_markables.xml'))\n",
    "    moves_root = moves_tree.getroot()\n",
    "    moves_spans = defaultdict(list)\n",
    "    success_move = {}\n",
    "    i = 0\n",
    "    for move in moves_root:\n",
    "        id_move = move.attrib['span'].replace('word_', '').split('..')\n",
    "        try:\n",
    "            success = move.attrib['move_world']\n",
    "        except:\n",
    "            success = move.attrib['world']\n",
    "        if len(id_move) == 2:\n",
    "            id_move = (int(id_move[0]), int(id_move[1]))\n",
    "        else:\n",
    "            id_move = (int(id_move[0]), int(id_move[0]))\n",
    "        moves_spans[i] = id_move\n",
    "        success_move[id_move] = success\n",
    "        i += 1\n",
    "    utt_tree = ET.parse(path.join(markables, dialogue + '_utterance_markables.xml'))\n",
    "    utts_root = utt_tree.getroot()\n",
    "    utts_speaker = defaultdict(list)\n",
    "    for utt in utts_root:\n",
    "        span =  utt.attrib['span'].replace('word_', '').split('..')\n",
    "        if len(span) == 2:\n",
    "            span = (int(span[0]), int(span[1]))\n",
    "        else:\n",
    "            span = (int(span[0]), int(span[0]))\n",
    "        speaker =  utt.attrib['speaker']\n",
    "        utts_speaker[speaker].append(span)\n",
    "    #associate referring expressions to objects\n",
    "    ref_tree = ET.parse(path.join(markables, dialogue + '_ref_markables.xml'))\n",
    "    refs_root = ref_tree.getroot()\n",
    "    refs_objects = defaultdict(list)\n",
    "    for ref in refs_root:\n",
    "        ref_type = ref.attrib['referent_type']\n",
    "        form =  ref.attrib['form']\n",
    "        span =  ref.attrib['span'].replace('word_', '').split('..')\n",
    "        if len(span) == 2:\n",
    "            span = (int(span[0]), int(span[1]))\n",
    "        else:\n",
    "            span = (int(span[0]), int(span[0]))\n",
    "        try:\n",
    "            item =  ref.attrib['item_id']\n",
    "            refs_objects[item].append((span, form, ref_type))\n",
    "        except:\n",
    "            pass\n",
    "    moves_utt = defaultdict(dict)\n",
    "    for s in utts_speaker:\n",
    "        for utt in utts_speaker[s]:\n",
    "            for m in moves_spans:\n",
    "                if utt[0] >= moves_spans[m][0] and utt[0] <= moves_spans[m][1]:\n",
    "                    if not moves_utt[moves_spans[m]].has_key(s):\n",
    "                        moves_utt[moves_spans[m]][s] = []\n",
    "                    moves_utt[moves_spans[m]][s].append(utt)\n",
    "    moves_ref = defaultdict(dict)\n",
    "    for obj in refs_objects:\n",
    "        speaker = ''\n",
    "        move = ''\n",
    "        for ref in refs_objects[obj]:\n",
    "            word_span = ref[0]\n",
    "            for m in moves_utt:\n",
    "                for s in moves_utt[m]:\n",
    "                    for utt in moves_utt[m][s]:\n",
    "                        if word_span[0] >= utt[0] and word_span[0] <= utt[1]:\n",
    "                            speaker = s\n",
    "                            move = m\n",
    "                            if not moves_ref[move].has_key(speaker):\n",
    "                                moves_ref[move][speaker] = {}\n",
    "                            if not moves_ref[move][speaker].has_key(obj):\n",
    "                                moves_ref[move][speaker][obj] = []\n",
    "                            moves_ref[move][speaker][obj].append(ref)\n",
    "                            break\n",
    "    moves_ref_words = defaultdict(dict)\n",
    "    for m in moves_ref:\n",
    "        for s in moves_ref[m]:\n",
    "            for o in moves_ref[m][s]:\n",
    "                for ref in moves_ref[m][s][o]:\n",
    "                    span = ref[0]\n",
    "                    form = ref[1]\n",
    "                    ref_type = ref[2]\n",
    "                    if len(span) == 1:\n",
    "                        exp = words[span[0]]\n",
    "                    else:\n",
    "                        exp = ''\n",
    "                        i = span[0]\n",
    "                        while i <= span[1]:\n",
    "                            if i != span[1]:\n",
    "                                exp += words[i] + ' '\n",
    "                            else:\n",
    "                                exp += words[i]\n",
    "                            i += 1\n",
    "                    if not moves_ref_words[m].has_key(s):\n",
    "                        moves_ref_words[m][s] = {}\n",
    "                    if not moves_ref_words[m][s].has_key(o):\n",
    "                        moves_ref_words[m][s][o] = {}\n",
    "                    if not moves_ref_words[m][s][o].has_key(ref_type):\n",
    "                        moves_ref_words[m][s][o][ref_type] = []\n",
    "                    #remove hesitations, and internal tags\n",
    "                    exp = re.sub(r'<.*>', '', exp)\n",
    "                    exp = re.sub(r'</.*>', '', exp)\n",
    "                    exp = re.sub(r'\\(.*\\)', '', exp)\n",
    "                    exp = re.sub(r'[\\(\\)\\[\\]\\.]','', exp)\n",
    "                    exp = exp.lower()\n",
    "                    exp_sp = exp.split(' ')\n",
    "                    if len(exp_sp) == 1 and exp.endswith(\"'s\"):\n",
    "                        exp = exp.replace(\"'s\", '')\n",
    "                    moves_ref_words[m][s][o][ref_type].append((exp, span, form))\n",
    "            for t in moves_ref_words[m][s][o]:\n",
    "                moves_ref_words[m][s][o][t] = sorted(moves_ref_words[m][s][o][ref_type], key=lambda tup: tup[1][0])\n",
    "    moves_ref_words = sorted(moves_ref_words.items())\n",
    "    return moves_ref_words, success_move\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Disruption_with_Noise_Corpus', 'Push_to_Talk_Corpus', 'Visual_Pento_Corpus']\n",
      "20061117_run1pento_noise\n",
      "20061117_run2pento_noise\n",
      "20061123_pento_nonoise\n",
      "20070117_run1pento_noise\n",
      "20070131_run1pento_noise\n",
      "20070131_run2pento_noise\n",
      "20070201_run1pento_nonoise\n",
      "20070201_run3pento_nonoise\n",
      "20070201_run4pento_nonoise\n",
      "FTT_2006-02-13pair1\n",
      "FTT_2006-03-27Pair1\n",
      "FTT_2006-03-28pair2\n",
      "FTT_2006-06-22pair1\n",
      "FTT_2006-06-22pair2\n",
      "PTT_2006-02-13pair2a\n",
      "PTT_2006-03-27Pair2a\n",
      "PTT_2006-03-27pair3a\n",
      "PTT_2006-03-28pair1\n",
      "PTT_2006-06-22pair3a\n",
      "run1605_002b\n",
      "run1605_003b\n",
      "run1605_004b\n",
      "run1605_005b\n",
      "run1605_006b\n",
      "run1605_007b\n"
     ]
    }
   ],
   "source": [
    "#associate word ids to words\n",
    "\n",
    "data_folder = 'PentoCorpora'\n",
    "games = listdir(data_folder)\n",
    "print games\n",
    "for g in games:\n",
    "    folder = path.join(data_folder, g)\n",
    "    basedata = path.join(folder, 'Basedata')\n",
    "    markables = path.join(folder,'Markables')\n",
    "    dialogues = []\n",
    "    output_folder = g.replace('/', '.')\n",
    "    output_folder = path.join('Dataset', output_folder)\n",
    "    for doc in listdir(basedata):\n",
    "        if doc.endswith('_words.xml'):\n",
    "            dialogue = doc.replace('_words.xml', '')\n",
    "            dialogues.append(dialogue)\n",
    "    try:\n",
    "        stat(output_folder)\n",
    "    except:\n",
    "        makedirs(output_folder)\n",
    "    try:\n",
    "        stat(output_folder+ '/RefExp')\n",
    "    except:\n",
    "        makedirs(output_folder+ '/RefExp')\n",
    "    try:\n",
    "        stat(output_folder+ '/Success')\n",
    "    except:\n",
    "        makedirs(output_folder+ '/Success')\n",
    "    for d in dialogues:\n",
    "        try: \n",
    "            r, s = extract_info(d)\n",
    "            pickle.dump(r, open( path.join(output_folder + '/RefExp', d + \"_refexps.p\"), \"wb\" ) )\n",
    "            pickle.dump(s, open( path.join(output_folder + '/Success', d + \"_movesuccess.p\"), \"wb\" ) )\n",
    "            print d\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(dialogue_path):\n",
    "    with open(dialogue_path) as handle:\n",
    "        d = pickle.load(handle)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def move_level(d_refexps):\n",
    "    new = {}\n",
    "    for m in d_refexps:\n",
    "        move, d = m\n",
    "        for s in d:\n",
    "            for o in d[s]:\n",
    "                for r in d[s][o]:\n",
    "                    for exp in d[s][o][r]:\n",
    "                        if not new.has_key(move):\n",
    "                            new[move] = {}\n",
    "                        if not new[move].has_key((o,r)):\n",
    "                            new[move][(o,r)] = []\n",
    "                        text, span, form = exp\n",
    "                        exp = (span, s, text, form)\n",
    "                        new[move][(o,r)].append(exp)\n",
    "        for t in new[move]:\n",
    "            new[move][t] = sorted(new[move][t], key=lambda tup: tup[0][0])\n",
    "    new = sorted(new.items())\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_previous(refexp, obj_refexps):\n",
    "    '''\n",
    "    input: refexp, list of refexps tuples referring to an object\n",
    "    output: previous refexp by different speaker with that object\n",
    "    '''\n",
    "    i = obj_refexps.index(refexp) - 1\n",
    "    speaker = refexp[1]\n",
    "    previous = 'no_previous'\n",
    "    while i >= 0:\n",
    "        if obj_refexps[i][1] != speaker:\n",
    "            previous = obj_refexps[i]\n",
    "            break\n",
    "        i =- 1\n",
    "    return previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer('german')\n",
    "ignore_words = stopwords.words('german')\n",
    "ignore_words.extend(['dis', \"'n\"])\n",
    "from string import punctuation\n",
    "punct = list(punctuation)\n",
    "\n",
    "def lex_material(exp):\n",
    "    exp = exp[2]\n",
    "    words = word_tokenize(exp) \n",
    "    content_words = set()\n",
    "    for w in words:\n",
    "        w = stemmer.stem(w)\n",
    "        if not w in punct:\n",
    "            stopword = False\n",
    "            for sw in ignore_words:\n",
    "                if sw == w:\n",
    "                    stopword = True\n",
    "            if stopword == False:\n",
    "                content_words.add(w)\n",
    "    return content_words\n",
    "\n",
    "def lex_sim(exp1, exp2):\n",
    "    words1 = lex_material(exp1)\n",
    "    words2 = lex_material(exp2)\n",
    "    try:\n",
    "        diff = 1 - float(2*len(words1.intersection(words2)))/float(len(words1)+ len(words2))\n",
    "        print diff\n",
    "    except:\n",
    "        diff = 'undefined'\n",
    "    return dice_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gamerun_level(d_refexps):\n",
    "    new = {}\n",
    "    for m in d_refexps:\n",
    "        move, d = m\n",
    "        for s in d:\n",
    "            for o in d[s]:\n",
    "                for r in d[s][o]:\n",
    "                    for exp in d[s][o][r]:\n",
    "                        if not new.has_key((o,r)):\n",
    "                            new[(o,r)] = []\n",
    "                        text, span, form = exp\n",
    "                        exp = (span, s, text, form)\n",
    "                        new[(o,r)].append(exp)\n",
    "    for t in new:\n",
    "        new[t] = sorted(new[t], key=lambda tup: tup[0][0])\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'dice_sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-ca1556018780>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mget_previous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'no_previous'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlex_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_previous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;31m#print sim, refobj[i], get_previous(refobj[i], refobj), o\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'undefined'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-fc132e9cf6cd>\u001b[0m in \u001b[0;36mlex_sim\u001b[0;34m(exp1, exp2)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'undefined'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdice_sim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: global name 'dice_sim' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "dialogue = 'Dataset/Push_to_Talk_Corpus/RefExp/FTT_2006-02-13pair1_refexps.p'\n",
    "d = load_data(dialogue)\n",
    "refexps = gamerun_level(d)\n",
    "diffs = []\n",
    "for o in refexps:\n",
    "    refobj = refexps[o]\n",
    "    i = 1\n",
    "    while i< len(refobj):\n",
    "        if get_previous(refobj[i], refobj) != 'no_previous':\n",
    "            diff = lex_sim(refobj[i], get_previous(refobj[i], refobj))\n",
    "            #print sim, refobj[i], get_previous(refobj[i], refobj), o\n",
    "            if diff != 'undefined':\n",
    "                diffs.append(sim)\n",
    "        i += 1\n",
    "print np.mean(diffs)\n",
    "#print refobj\n",
    "#refexps = gamerun_level(d)\n",
    "\n",
    "'''\n",
    "def player_level(d_refexps): use the other function\n",
    "def lex_sim(ref_exps):\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
